<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    <title>Weize Li - Homepage</title>
    
    <meta name="author" content="Weize Li">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
</head>

<body>
    <table style="width:100%;max-width:900px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:middle">
                <p style="text-align:center">
                  <name>Weize Li (李维泽)</name>
                </p>
                <p style="text-align:justify;">
                  I am currently spending my gap year as a research intern student at <a href="http://www.lightillusions.com/"><b>Lightillusions</b></a> and <a href="https://air.tsinghua.edu.cn/en/"><b>Institute for AI Industry Research (AIR), Tsinghua University</b></a>.
                  I am fortunate to work closely with <a href="https://www.xxlong.site/">Dr. Xiaoxiao Long</a> from <a href="https://www.hku.hk/">HKU</a>, <a href="https://ece.hkust.edu.hk/pingtan">Prof. Ping Tan</a> from <a href="https://hkust.edu.hk/">HKUST</a>, and <a href="https://sites.google.com/view/fromandto">Prof. Hao Zhao</a> from <a href="https://www.discover-lab.com/">DISCOVER Lab</a>. 
                  Previously, I was a visiting student at <a href="http://english.ia.cas.cn/">Institute of Automation, Chinese Academy of Sciences</a> in my senior year.
                  And I got my B.Eng. in Mechatronics Engineering from Beijing University of Civil Engineering and Architecture.
		<p>
		  I am an active member of <a href="https://anysyn3d.github.io/">AnySyn3D</a>, a non-profit research interest group comprising individuals with a strong interest in exploring research problems and cutting-edge technologies in any topics of 3D.
                  </p>
                  <p>
                  <b><strong>I am actively looking for the PhD opportunity in Fall 2025.</strong></b>
                  </p>
                <p style="text-align:center">
                    <a href="mailto:liweize0224@gmail.com"><b>Email</b></a> &nbsp/&nbsp
                    <a href="WeizeLi_04.02.pdf"><b>CV</b></a> &nbsp/&nbsp
                    <a href="https://scholar.google.com/citations?user=CyPiUucAAAAJ&hl=en-US"><b>Google Scholar</b></a> &nbsp/&nbsp
                    <a href="https://github.com/EricLee0224/"><b>GitHub</b></a> &nbsp/&nbsp
                    <a href="https://twitter.com/WeizeLi24"><b>X</b></a>
                </p>
              </td>
              <td style="padding:2.5%;width:48%;max-width:48%">
                <img style="width:100%;max-width:100%;object-fit: cover; border-radius: 50%;" alt="profile photo" src="images/avator.jpg" class="hoverZoomLink"></a>
              </td>
	      </tr>
	      </table>
	
<!-- -------------------------- NEWS ------------------------------ -->

<!-- <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
  <tr>
  <td style="padding:20px;width:100%;vertical-align:middle">
    <heading>News</heading>
    <p>
      <li style="margin: 5px;" >
        <b>2023-09:</b>🎉PAD was accepted to NeurIPS 2023 as Poster!
      </li>
      <li style="margin: 5px;" >
        <b>2023-08:</b>😎Welcome to <a href="https://github.com/EricLee0224/awesome-nerf-editing">awesome-nerf-editing</a>, find resource for exploring 3D editing!
      </li>
      <li style="margin: 5px;" >
        <b>2023-06:</b>👨‍🎓<a href="https://pku.ai/">PKU CoRe Lab</a> Visiting! Many thanks to Prof. <a href="https://yzhu.io/">Yixin Zhu</a>'s advices on my future study.
      </li>
      <li style="margin: 5px;" >
        <b>2023-02:</b>🎉IRFLMDNN was accepted to Neural Computing & Applications!
      </li>
      <li style="margin: 5px;" >
        <b>2022-10:</b>🎉My graduation dissertation was selected as 2022 Beijing Outstanding Undergraduate Dissertation Award (top1%)!
      </li>
      <li style="margin: 5px;" >
        <b>2022-10:</b>🎉I successfully defended Summer Research: McADTR. Thanks to my advisors and Prof. <a href="https://ericyi.github.io/">Li Yi</a>'s insightful comments.
      </li>
      <li style="margin: 5px;" >
        <b>2022-08:</b>😮‍💨I finished my visiting at CASIA and it was a pleasure to work with Lei, Yu, Xiaomeng and Xiaomin!
      </li>
    </p>
  </td>
</tr>
</tbody></table> -->

<!--  ------------------------ Research ------------------------------>
<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
  <tr>
  <td style="padding:20px;width:100%;vertical-align:middle">
    <heading>Research</heading>
    <p style="text-align:justify;">
      My long-term research goal is to build <strong>Embodied Intelligent Systems</strong> that connect humans👫, machines🤖, and the real world🌏 through perception, simulation, and interaction. 
      I believe the key lies in leveraging structured human languages🗣️ to help machines use 3D visual data to learn how to perceive, reason, and act in both virtual and real world. 
      So I am currently focusing on <strong>{3D Vision, Graphics, Robotics} for Embodied AI</strong>.
    </p>
    <p>
      <li style="margin: 5px;"> 
        👀<strong>3D Vision for Embodied Perception:</strong>
	<br>3D Scene Understanding; Grounded Vision-Language (e.g.grounding, dense captioning, VQA); <S>Anomaly Detection</S>.
      </li>
	    
      <li style="margin: 5px;"> 
        🪅<strong>Graphics for Embodied Simulation:</strong> 
	<br>3D Scene/Object Reconstruction, Text/Image-guided Generation and Text-guided Editing.
      </li>
	    
      <li style="margin: 5px;"> 
        🤖<strong>Robotics for Embodied Interaction:</strong> 
	<br>Low-level Manipulation; High-level Task Planning; Autonomous Driving.
      </li>
    </p>
  </td>
</tr>

<!--  ----------------------- PUBLICATIONS --------------------------  -->

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Publications</heading>
            </td>
          </tr>
<!-- 	(<sup>†</sup>: corresponding author; <sup>*</sup>: equal contribution) -->
        </tbody></table>	
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
	(<sup>†</sup>: corresponding author; <sup>*</sup>: equal contribution)
          <tr>
            <td style="padding:14px;width:30%;max-width:30%" align="center">
                <img style="width:100%;max-width:100%" src="./images/tod3cap.png" alt="dise">
            </td>
            <td width="75%" valign="center">
              <papertitle><a href="https://arxiv.org/abs/2403.19589"><b>TOD3Cap: Towards 3D Dense Captioning in Outdoor Scenes.</b></a></papertitle>
              <br>
                                                                <a href="https://scholar.google.com/citations?user=uUd5v2cAAAAJ&hl=en">Bu Jin</a>,
								<a href="https://scholar.google.com/citations?user=anGhGdYAAAAJ&hl=en">Yupeng Zheng<sup>†</sup></a>,
								<a href="https://github.com/Philipflyg">Pengfei Li</a>,
								<strong>Weize Li</strong>,
								<a href="https://scholar.google.com/citations?user=Wn2Aic0AAAAJ&hl=en">Yuhang Zheng</a>,
		                                                et al.,
		                                                <a href="https://www.xxlong.site/">Xiaoxiao Long</a>,
		                                                <a href="https://air.tsinghua.edu.cn/en/info/1046/1621.htm">Yilun Chen</a>,
		                                                <a href="https://sites.google.com/view/fromandto">Hao Zhao</a>.
              <br>
              <strong><em>ECCV 2024</em></strong>
              <br>
              <a href="https://arxiv.org/abs/2403.19589"><b>[arXiv]</b></a>
	      <a href="https://github.com/jxbbb/TOD3Cap"><b>[Code]</b></a>
	      <br>
              [<a style="color: red;">Special Ack.</a> to <a href="https://daveredrum.github.io/">Dave Zhenyu Chen</a>@TUM for valuable proofreading and insightful suggestions.</a>]
	      <p>We introduce the new task of outdoor 3D dense captioning with TOD3Cap dataset; We propose TOD3Cap network, leveraging the BEV representation to encode sparse outdoor scenes, and combine Relation Q-Former with LLaMA-Adapter to dense captioning in the open-world.</p>	
          </tr>
		
          <tr>
            <td style="padding:14px;width:30%;max-width:30%" align="center">
                <img style="width:100%;max-width:100%" src="./images/pad.png" alt="dise">
            </td>
            <td width="75%" valign="center">
              <papertitle><a href="https://openreview.net/forum?id=kxFKgqwFNk"><b>PAD: A Dataset and Benchmark for Pose-agnostic Anomaly Detection</b></a></papertitle>
              <br>
		    						<a href="https://scholar.google.com/citations?user=CMYTxUEAAAAJ&hl=en/">Qiang Zhou<sup>*</sup></a>,
              							<strong>Weize Li<sup>*</sup></strong>,
								<a href="https://jianglh-whu.github.io/">Lihan Jiang</a>,
								<a href="https://github.com/Cross-ZBuild">Guoliang Wang</a>,
								<a href="https://air.tsinghua.edu.cn/en/info/1046/1196.htm">Guyue Zhou</a>,
								<a href="https://www.shanghangzhang.com/">Shanghang Zhang</a>,
								<a href="https://sites.google.com/view/fromandto">Hao Zhao</a>.
              <br>
              <strong><em>NeurIPS 2023 Dataset and Benchmark Track (<a style="color: red;">Poster</a>)</em></strong>
              <br>
              <a href="https://arxiv.org/abs/2310.07716"><b>[arXiv]</b></a>
              <a href="https://github.com/EricLee0224/PAD#4-omniposead"><b>[Code]</b></a>
              <a href="https://github.com/EricLee0224/PAD"><b>[Dataset]</b></a>
              <br>
	      <p>We introduce pose-agnostic setting to 3D-aware object anomaly detection problem with MAD dataset, propose the NeRF-based anomaly detection framework: OmniposeAD.</p>
            </td>
          </tr>
		
         <tr>
            <td style="padding:14px;width:30%;max-width:30%" align="center">
                <img style="width:100%;max-width:100%" src="./images/irflmdnn.png" alt="dise">
            </td>
            <td width="75%" valign="center">
              <papertitle><a href="https://dl.acm.org/doi/abs/10.1007/s00521-023-08571-4"><b>IRFLMDNN: Hybrid Model for PMU Data Anomaly Detection and Re-filling with Improved Random Forest and Levenberg Marquardt Algorithm Optimized Dynamic Neural Network.</b></a></papertitle>
              <br>
              <a href="http://faculty.bucea.edu.cn/pub/yumiao/">Miao Yu<sup>†</sup></a>,
								<a>Chenyu Yang<sup>*</sup></a>,
								<strong>Weize Li<sup>*</sup></strong>,
								<a>Weijie Du</a>,
								<a>Jinglin Li</a>.
              <br>
              <strong><em>Neural Computing and Application 2023</em></strong>
              <br>
              <a href="https://dl.acm.org/doi/abs/10.1007/s00521-023-08571-4"><b>[paper]</b></a>
              <br>
              <p>We propose a hybrid model of improved RF + DNN to extract time-series features and classify anomalies in power system data.</p>
            </td>
          </tr>

<!--  ------------------------ Patents --------------------------  -->
  
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Patents</heading>
              <p>
                <li style="margin: 5px;"> 
                  <b>Power low frequency oscillation data anomaly monitoring system v1.0[s]</b>, CN Software Patent No.2022SR0277090
                </li>
                <li style="margin: 5px;"> 
                  <b>Power low frequency oscillation data acquisition system v1.0[s]</b>, CN Software Patent No.2022SR0281546
                </li>
              </p>
            </td>
          </tr>
        </tbody></table>
		
<!--  ------------------------ PROJECTS --------------------------  -->

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <heading>Selected Projects</heading>
              </td>
            </tr>
          </tbody></table>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

            <tr>
              <td style="padding:14px;width:30%;max-width:30%" align="center">
                  <img style="width:100%;max-width:100%" src="./images/survey_teaser.jpg" alt="dise">
              </td>
              <td width="75%" valign="center">
                <papertitle><b>Radiance Field-Based 3D Editing: A Survey</b></papertitle>
                <br>
              				<strong>Weize Li<sup>*</sup></strong>,
					<a href="https://tianshukuai.github.io/">Tianshu Kuai<sup>*</sup></a>,
					<a href="https://c7w.tech/about/">Huan-ang Gao</a>,
					<a href="https://www.eca.ed.ac.uk/profile/trina-tian">Siyu Tian</a>,
					<a href="https://scholar.google.com/citations?user=Wn2Aic0AAAAJ&hl=en">Yuhang Zheng</a>,
					<a href="https://scholar.google.com/citations?user=anGhGdYAAAAJ&hl=en">Yupeng Zheng</a>,etc.
		<br>
                <strong><em>On-going, 2024</em></strong>
                <br>
                <a href="https://github.com/EricLee0224/awesome-nerf-editing"><b>[Project Page]</b></a>
		<br>
                <p>This is an ongoing survey paper and we are conducting a systematic classification and in-depth analysis for 3D content editing based on radiance field representations (including NeRFs, 3DGS, etc.).</p>
              </td>
            </tr>

            <tr>
                <td style="padding:14px;width:30%;max-width:30%" align="center">
                    <img style="width:100%;max-width:100%" src="./images/zero12car.png" alt="dise">
                </td>
                <td width="75%" valign="center">
                    <papertitle><b>Zero1-to-Car: Finetuning Zero1-to-3 for Single Vehicle Image to 3D.</b></papertitle>
                    <br>
		    <em>AIR Research Project. 2023</em>
		    <br>
                    <a href="https://github.com/EricLee0224/"><b>[Coming soon]</b></a>
		    <br>
                    <p>Investigated one‑image‑to‑3D methods like Zero1‑to‑3 to enhance the quality of multi‑view car instances in simulation scenes, with a focus on fine‑tuning models using the ”Car” labeled 3D assets from the Objaverse dataset.</p>
                </td>

		 <tr>
              <td style="padding:14px;width:30%;max-width:30%" align="center">
                  <img style="width:100%;max-width:100%" src="./images/mcadtr.png" alt="dise">
              </td>
              <td width="75%" valign="center">
                <papertitle><b>McADTR: Multi-class Anomaly Detection TRansformer with Heterogenous Knowledge Distillation.</b></papertitle>
                <br>
		<em>AIR Summer Research 2022</em>
		<br>
                <a href="https://github.com/EricLee0224/McADTR"><b>[Code]</b></a>
		<br>
                <p>This project proposes a unified framework for visual anomaly detection based on heterogeneous knowledge distillation. The One-model-all class framework merges CNN and ViT with class-specific learnable query to enable mutually facilitated learning of anomalous features across multi-class samples.</p>
              </td>
            </tr>
		
            </tr>

        <!--  ------------------------ Service -------------------------- -->
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
          <td style="padding:20px;width:100%;vertical-align:middle">
            <heading>Service</heading>
            <p style="text-align:justify;">
              I served / was delegated as Reviewer for NeurIPS’23, CVPR’24, IJCV.
            </p>
          </td>
        </tr>
		  
<!--  ------------------------ AWARDS --------------------------  -->
  
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Awards</heading>
              <p>
                <li style="margin: 5px;"> 
                  <b>Outstanding Undergraduate Dissertation Award, Beijing Education Commission (top 1% in 130,000 students, 2022)</b>
                </li>
                <li style="margin: 5px;"> 
                  Silver Award, Beijing Challenge Cup: Entrepreneurial Plan Competition in AI System Track (Rank.2, 2022)
                </li>
              </p>
            </td>
          </tr>
        </tbody></table>

        <!--  ------------------------ MISC -------------------------- -->
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
          <td style="padding:20px;width:100%;vertical-align:middle">
            <heading>Misc.</heading>
            <p style="text-align:justify;">
              Outside of research, I enjoy playing football⚽, fitness💪 and photography📷. I am a member of the Certified Referee🗣️ Crew of the Chinese Football Association. I am also a big fan of Taylor Swift🦋.
            </p>
          </td>
        </tr>

        <!-- ------------------------ LOGOS -------------------------- -->
        <!-- <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:1%;width:20%;vertical-align:middle;">
              <a href="https://www.tsinghua.edu.cn/"><img style="width:105%;max-width:105%" src="images/tsinghua.jpg" alt="dise"></a>
            </td>
            <td style="padding:2.8%;width:20%;vertical-align:middle;">
              <a href="https://www.northwestern.edu"><img style="width:111.5%;max-width:111.5%" src="images/northwestern.jpg" alt="dise"></a>
            </td>
          </tr> -->
		
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:right;">
                  Website template from <a href="https://jonbarron.info/">Jon Barron</a>.
              </p>
            </td>
          </tr>
        </tbody></table>

        </td>
      </tr>
    </table>
   
    <p><center>
            <div id="clustrmaps-widget" style="width:6%">
              <script type="text/javascript" id="clstr_globe" src="//clustrmaps.com/globe.js?d=b7mtyQom9p7zsZIJHjY71xt4m7fiicjvzctV6CkNA-s"></script>
            </div>        
            <br>
            &copy; Weize Li | Last update: April.30, 2024
    </center></p>
  </body>
</html>
