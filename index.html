<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    <title>Weize Li - ÊùéÁª¥Ê≥Ω</title>
    
    <meta name="author" content="Weize Li">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
</head>

<body>
    <table style="width:100%;max-width:900px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:middle">
                <p style="text-align:center">
                  <name>Weize Li - ÊùéÁª¥Ê≥Ω</name>
                </p>
                <p style="text-align:justify;">
                  I am currently spending my gap year as a research intern student at <a href="https://air.tsinghua.edu.cn/en/"><b>Institute for AI Industry Research (AIR), Tsinghua University</b></a>.
                  I am advised by Prof. <a href="https://sites.google.com/view/fromandto">Hao Zhao</a> from <a href="https://www.discover-lab.com/">DISCOVER Lab</a>. 
                  Previously, I was a visiting student in <a href="http://english.ia.cas.cn/rd/200908/t20090807_27609.html">Integrated Information System Research Center</a> at <a href="http://english.ia.cas.cn/">Institute of Automation, Chinese Academy of Sciences</a>.
                  I was an undergraduate in the Department of Mechanical-Electronic & Vehicle Engineering at Beijing University of Civil Engineering and Architecture, advised by Prof. <a href="http://faculty.bucea.edu.cn/pub/yumiao/">Miao Yu</a>.
                  My research interests are in the field of computer vision, graphics and robotics.

                </p>
                <p>
                  <b>I am looking for a PhD opportunity for Fall 2024 intake.</b>
                </p>
                <p style="text-align:center">
                    <a href="mailto:liweize0224@gmail.com"><b>Email</b></a> &nbsp/&nbsp
                    <a href="WeizeLi_04.02.pdf"><b>CV</b></a> &nbsp/&nbsp
                    <a href="https://scholar.google.com/citations?user=CyPiUucAAAAJ&hl=en-US"><b>Google Scholar</b></a> &nbsp/&nbsp
                    <a href="https://github.com/EricLee0224/"><b>GitHub</b></a> &nbsp/&nbsp
                    <a href="https://twitter.com/WeizeLi24"><b>Twitter</b></a>
                </p>
              </td>
              <td style="padding:2.5%;width:48%;max-width:48%">
                <img style="width:100%;max-width:100%;object-fit: cover; border-radius: 50%;" alt="profile photo" src="images/avator.jpg" class="hoverZoomLink"></a>
              </td>
            </tr>
          </tbody></table>

<!-- -------------------------- NEWS ------------------------------ -->

<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
  <tr>
  <td style="padding:20px;width:100%;vertical-align:middle">
    <heading>News</heading>
    <p>
      <li style="margin: 5px;" >
        <b>2023-09:</b>üéâPAD was accepted to NeurIPS 2023 as Poster!
      </li>
      <li style="margin: 5px;" >
        <b>2023-08:</b>üòéWelcome to <a href="https://github.com/EricLee0224/awesome-nerf-editing">awesome-nerf-editing</a>, find resource for exploring 3D editing!
      </li>
      <li style="margin: 5px;" >
        <b>2023-06:</b>üë®‚Äçüéì<a href="https://pku.ai/">PKU CoRe Lab</a> Visiting! Many thanks to Prof. <a href="https://yzhu.io/">Yixin Zhu</a>'s advices on my future study.
      </li>
      <li style="margin: 5px;" >
        <b>2023-02:</b>üéâIRFLMDNN was accepted to Nerual Computing & Applications!
      </li>
      <li style="margin: 5px;" >
        <b>2022-10:</b>üéâMy graduation thesis was selected as 2022 Beijing Outstanding Undergraduate Thesis Award (top1%)!
      </li>
      <li style="margin: 5px;" >
        <b>2022-10:</b>üéâI successfully defended Summer Research: McADTR. Thanks to my advisors and Prof. <a href="https://ericyi.github.io/">Li Yi</a>'s insightful comments.
      </li>
      <li style="margin: 5px;" >
        <b>2022-08:</b>üòÆ‚Äçüí®I finished my visiting at CASIA and it was a pleasure to work with Lei, Yu, Xiaomeng and Xiaomin!
      </li>
    </p>
  </td>
</tr>
</tbody></table>

<!--  ------------------------ Research ------------------------------>
<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
  <tr>
  <td style="padding:20px;width:100%;vertical-align:middle">
    <heading>Research</heading>
    <p style="text-align:justify;">
      My long-term research goal is to build agents that can effectively understand 3D worlds based on vision and be able to combine visual concepts and external knowledge for interpretable reasoning. 
      Further, being able to apply the learned knowledge from reconstruction to generation and editing the digital world, towards the ultimate goal from understanding to changing the world. 
      So I am up for anything related research and currently focusing on:
    </p>
    <p>
      <li style="margin: 5px;"> 
        üëÄ<strong>Vision:</strong> 3D scene understanding with multi-modal; Visual-grounded reasoning; <S>Anomaly Detection</S>.
      </li>
      <li style="margin: 5px;"> 
        ü™Ö<strong>Graphics:</strong> Scene representations (NeRFs, 3DGS); 3D scene/object reconstruction, generation and editing.
      </li>
      <li style="margin: 5px;"> 
        ü§ñ<strong>Robotics:</strong> Embodied AI; Robot manipulation; Interpretable planning with LLMs.
      </li>
    </p>
  </td>
</tr>

<!--  ----------------------- PUBLICATIONS --------------------------  -->

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Publications</heading>
            </td>
          </tr>
	(<sup>‚Ä†</sup>: corresponding author; <sup>*</sup>: equal contribution)
        </tbody></table>	
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

          <tr>
            <td style="padding:14px;width:30%;max-width:30%" align="center">
                <img style="width:100%;max-width:100%" src="./images/tod3cap.png" alt="dise">
            </td>
            <td width="75%" valign="center">
              <papertitle><a href="https://arxiv.org/abs/2403.19589"><b>TOD3Cap: Towards 3D Dense Captioning in Outdoor Scenes.</b></a></papertitle>
              <br>
                                                                <a>Bu Jin</a>,
								<a>Yupeng Zheng</a>,
								<a href="https://github.com/Philipflyg">Pengfei Li</a>,
								<strong>Weize Li</strong>,
								<a>Yuhang Zheng</a>,
		                                                et al.,
		                                                <a href="https://www.xxlong.site/">Xiaoxiao Long</a>,
		                                                <a href="https://air.tsinghua.edu.cn/en/info/1046/1621.htm">Yilun Chen</a>,
		                                                <a href="https://sites.google.com/view/fromandto">Hao Zhao</a>.
              <br>
              <strong><em>Under Review, 2024</em></strong>
              <br>
              <a href="https://arxiv.org/abs/2403.19589"><b>[arXiv]</b></a>
	      <a href="https://github.com/jxbbb/TOD3Cap"><b>[Code]</b></a>
	      <br>
              [<a style="color: red;">Special Ack.</a> to <a href="https://daveredrum.github.io/">Dave Zhenyu Chen</a>@TUM for valuable proofreading and insightful suggestions.</a>]
	      <p>We introduce the new task of outdoor 3D dense captioning with TOD3Cap dataset; We propose TOD3Cap network, leveraging the BEV representation to encode sparse outdoor scenes, and combine Relation Q-Former with LLaMA-Adapter to dense captioning in the open-world.</p>	
          </tr>
		
          <tr>
            <td style="padding:14px;width:30%;max-width:30%" align="center">
                <img style="width:100%;max-width:100%" src="./images/pad.png" alt="dise">
            </td>
            <td width="75%" valign="center">
              <papertitle><a href="https://openreview.net/forum?id=kxFKgqwFNk"><b>PAD: A Dataset and Benchmark for Pose-agnostic Anomaly Detection</b></a></papertitle>
              <br>
              <a href="https://scholar.google.com/citations?user=CMYTxUEAAAAJ&hl=en/">Qiang Zhou<sup>*</sup></a>,
								<strong>Weize Li<sup>*</sup></strong>,
								<a href="https://jianglh-whu.github.io/">Lihan Jiang</a>,
								<a href="https://github.com/Cross-ZBuild">Guoliang Wang</a>,
								<a href="https://air.tsinghua.edu.cn/en/info/1046/1196.htm">Guyue Zhou</a>,
								<a href="https://www.shanghangzhang.com/">Shanghang Zhang</a>,
								<a href="https://sites.google.com/view/fromandto">Hao Zhao</a>.
              <br>
              <strong><em>NeurIPS 2023 Dataset and Benchmark Track (<a style="color: red;">Poster</a>)</em></strong>
              <br>
              <a href="https://arxiv.org/abs/2310.07716"><b>[arXiv]</b></a>
              <a href="https://github.com/EricLee0224/PAD#4-omniposead"><b>[Code]</b></a>
              <a href="https://github.com/EricLee0224/PAD"><b>[Dataset]</b></a>
              <br>
	      <p>We introduce pose-agnostic setting to 3D-aware object anomaly detection problem with MAD dataset, propose the NeRF-based anomaly detection framework: OmniposeAD.</p>
            </td>
          </tr>
		
         <tr>
            <td style="padding:14px;width:30%;max-width:30%" align="center">
                <img style="width:100%;max-width:100%" src="./images/irflmdnn.png" alt="dise">
            </td>
            <td width="75%" valign="center">
              <papertitle><a href="https://dl.acm.org/doi/abs/10.1007/s00521-023-08571-4"><b>IRFLMDNN: Hybrid Model for PMU Data Anomaly Detection and Re-filling with Improved Random Forest and Levenberg Marquardt Algorithm Optimized Dynamic Neural Network.</b></a></papertitle>
              <br>
              <a href="http://faculty.bucea.edu.cn/pub/yumiao/">Miao Yu<sup>‚Ä†</sup></a>,
								<a>Chenyu Yang<sup>*</sup></a>,
								<strong>Weize Li<sup>*</sup></strong>,
								<a>Weijie Du</a>,
								<a>Jinglin Li</a>.
              <br>
              <strong><em>Neural Computing and Application 2023</em></strong>
              <br>
              <a href="https://dl.acm.org/doi/abs/10.1007/s00521-023-08571-4"><b>[paper]</b></a>
              <br>
              <p>We propose a hybrid model of improved RF + DNN to extract time-series features and classify anomalies in power system data.</p>
            </td>
          </tr>

<!--  ------------------------ Patents --------------------------  -->
  
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Patents</heading>
              <p>
                <li style="margin: 5px;"> 
                  <b>Power low frequency oscillation data anomaly monitoring system v1.0[s]</b>, CN Software Patent No.2022SR0277090
                </li>
                <li style="margin: 5px;"> 
                  <b>Power low frequency oscillation data acquisition system v1.0[s]</b>, CN Software Patent No.2022SR0281546
                </li>
              </p>
            </td>
          </tr>
        </tbody></table>
		
<!--  ------------------------ PROJECTS --------------------------  -->

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <heading>Selected Projects</heading>
              </td>
            </tr>
          </tbody></table>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

            <tr>
              <td style="padding:14px;width:30%;max-width:30%" align="center">
                  <img style="width:100%;max-width:100%" src="./images/3d_edit_survey.png" alt="dise">
              </td>
              <td width="75%" valign="center">
                <papertitle><b>Advances in Radiance Fields: A Survey on 3D Editing</b></papertitle>
                <br>
		<em>[On-going] Free research with <a href="https://tianshukuai.github.io/"><b>Tianshu Kuai</b></a>, <a href="https://c7w.tech/about/"><b>Huan-ang Gao</b></a>, etc. 2024</em>
		<br>
                <a href="https://github.com/EricLee0224/awesome-nerf-editing"><b>[Project Page]</b></a>
		<br>
                <p>This is an ongoing survey paper and we are conducting a systematic classification and in-depth analysis for 3D content editing based on radiance field representations (including NeRFs, 3DGS, etc.).</p>
              </td>
            </tr>

            <tr>
                <td style="padding:14px;width:30%;max-width:30%" align="center">
                    <img style="width:100%;max-width:100%" src="./images/zero12car.png" alt="dise">
                </td>
                <td width="75%" valign="center">
                    <papertitle><b>Zero1-to-Car: Finetuning Zero1-to-3 for Single Vehicle Image to 3D.</b></papertitle>
                    <br>
		    <em>AIR Research Project. 2023</em>
		    <br>
                    <a href="https://github.com/EricLee0224/"><b>[Coming soon]</b></a>
		    <br>
                    <p>Investigated one‚Äëimage‚Äëto‚Äë3D methods like Zero1‚Äëto‚Äë3 to enhance the quality of multi‚Äëview car instances in simulation scenes, with a focus on fine‚Äëtuning models using the ‚ÄùCar‚Äù labeled 3D assets from the Objaverse dataset.</p>
                </td>

		 <tr>
              <td style="padding:14px;width:30%;max-width:30%" align="center">
                  <img style="width:100%;max-width:100%" src="./images/mcadtr.png" alt="dise">
              </td>
              <td width="75%" valign="center">
                <papertitle><b>McADTR: Multi-class Anomaly Detection TRansformer with Heterogenous Knowledge Distillation.</b></papertitle>
                <br>
		<em>AIR Summer Research 2022</em>
		<br>
                <a href="https://github.com/EricLee0224/McADTR"><b>[Code]</b></a>
		<br>
                <p>This project proposes a unified framework for visual anomaly detection based on heterogeneous knowledge distillation. The One-model-all class framework merges CNN and ViT with class-specific learnable query to enable mutually facilitated learning of anomalous features across multi-class samples.</p>
              </td>
            </tr>
		
            </tr>

        <!--  ------------------------ Service -------------------------- -->
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
          <td style="padding:20px;width:100%;vertical-align:middle">
            <heading>Service</heading>
            <p style="text-align:justify;">
              I served / was delegated as Reviewer for NeurIPS‚Äô23, CVPR‚Äô24.
            </p>
          </td>
        </tr>
		  
<!--  ------------------------ AWARDS --------------------------  -->
  
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Awards</heading>
              <p>
                <li style="margin: 5px;"> 
                  <b>Outstanding Undergraduate Thesis (Team-Track), Beijing Education Commission (top 1%, 2022)</b>
                </li>
                <li style="margin: 5px;"> 
                  Silver Award, Beijing Challenge Cup: Entrepreneurial Plan Competition in AI System Track, 2022
                </li>
              </p>
            </td>
          </tr>
        </tbody></table>

        <!--  ------------------------ MISC -------------------------- -->
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
          <td style="padding:20px;width:100%;vertical-align:middle">
            <heading>Misc.</heading>
            <p style="text-align:justify;">
              Outside of research, I enjoy playing football‚öΩ, fitnessüí™ and photographyüì∑. I am a member of the Certified Refereeüó£Ô∏è Crew of the Chinese Football Association. I am also a big fan of Taylor Swiftü¶ã.
            </p>
          </td>
        </tr>

        <!-- ------------------------ LOGOS -------------------------- -->
        <!-- <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:1%;width:20%;vertical-align:middle;">
              <a href="https://www.tsinghua.edu.cn/"><img style="width:105%;max-width:105%" src="images/tsinghua.jpg" alt="dise"></a>
            </td>
            <td style="padding:2.8%;width:20%;vertical-align:middle;">
              <a href="https://www.northwestern.edu"><img style="width:111.5%;max-width:111.5%" src="images/northwestern.jpg" alt="dise"></a>
            </td>
          </tr> -->
		
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:right;">
                  Website template from <a href="https://jonbarron.info/">Jon Barron</a>.
              </p>
            </td>
          </tr>
        </tbody></table>

        </td>
      </tr>
    </table>
   
    <p><center>
            <div id="clustrmaps-widget" style="width:6%">
              <script type="text/javascript" id="clstr_globe" src="//clustrmaps.com/globe.js?d=b7mtyQom9p7zsZIJHjY71xt4m7fiicjvzctV6CkNA-s"></script>
            </div>        
            <br>
            &copy; Weize Li | Last update: Mar.29, 2024
    </center></p>
  </body>
</html>
