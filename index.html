<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Weize Li - Homepage</title>
  <link href="css/bootstrap.css" rel='stylesheet' type='text/css' />
  <link rel="shortcut icon" type="image/x-icon" href="images/icon.png">
  <link href="https://fonts.googleapis.com/css?family=Open+Sans" rel="stylesheet">
  <!-- Bulma Version 0.7.5-->
  <link rel="stylesheet" href="https://unpkg.com/bulma@0.7.5/css/bulma.min.css" />
  <link href='css/style.css?_t=20200916' rel='stylesheet' type='text/css'>
  <script defer src="font-awesome/js/brands.min.js"></script>
  <script defer src="font-awesome/js/regular.min.js"></script>
  <script defer src="font-awesome/js/fontawesome.min.js"></script>
    <style>
      .red {
        color: rgb(238, 76, 44);
        font-style: normal;
      }
      .blue {
        color: rgb(238, 76, 44);
        font-style: normal;
      }
       
      #intro {
       margin-top: 0em !important;
      }
      
      .content h3 {
       margin-bottom: 1em!important;
       margin-top: 2em!important;
      }

      .content figure {
       width: 90%;
       display: flex;
       align-items: center;
       overflow: hidden;
       margin-left: auto!important;
       margin-right: auto!important;
      }
      
      .columns:not(:last-child) {
       margin-bottom: 1.75rem!important;
      }

      #sidebar {
        width: 75%;
      }

      @media screen and (min-width: 769px), print {
        .column.is-2_5, .column.is-2-tablet {
          flex: none;
          width: 20%;
        }
      }
</style>
    <script src="https://code.jquery.com/jquery-3.1.1.min.js" crossorigin="anonymous"></script>
</head>


<body>
  <section class="section">
    <div class="container">
      <div class="columns">
        <div class="column is-2_5">
          <div class="sticky">
            <figure class="image" style="width: 11.6rem; margin-top: 6px;">
              <img src="images/misc/profile.jpg">
            </figure>
            <div class="content">
              <h2 style="margin-top: 1em">Weize Li</h2>
              <p>
                <b>Student Researcher</b><br/> 
		            @ Lightillusions<br/> 
                @ AIR, Tsinghua University<br/>
                Beijing, China<br/> 
		            liweize0224@gmail.com
              </p>
            </div>
            <!-- social networks -->
            <div class="social">
              <a href="mailto:liweize0224@gmail.com" target="_blank">
                <span class="fa-regular fa-envelope fa-2x" style="display:inline; text-decoration: none; color: #4a4a4a; "></span>
              </a>
              <a href="https://github.com/EricLee0224/" target="_blank">
                <span class="fab fa-github fa-2x" style="display:inline; text-decoration: none; color: #4a4a4a; margin-left: 15px"></span>
              </a>
              <a href="https://scholar.google.com/citations?user=CyPiUucAAAAJ&hl=en-US" target="_blank">
                <span class="fa-brands fa-google fa-2x" style="display:inline; text-decoration: none; color: #4a4a4a; margin-left: 15px"></span>
              </a>
              <a href="https://twitter.com/WeizeLi24" target="_blank">
                <span class="fa-brands fa-twitter fa-2x" style="display:inline; text-decoration: none; color: #4a4a4a; margin-left: 15px"></span>
              </a>
            </div>


            <div id="sidebar" class="menu sticky is-hidden-mobile">
              <p class="menu-label"><b>Quick Links</b></p>
              <ul class="menu-list">  
                <li><a href="#Intro">About Me</a></li>
                <li><a href="#Research">Research</a></li>
                <li><a href="#Publications">Publication</a></li>
                <li><a href="#Projects">Project</a></li>
                <!-- <li><a href="#Experiences">Experiences</a></li> -->
                <li><a href="#Patents">Patent</a></li>
                <li><a href="#Awards">Award</a></li>
                <li><a href="#Service">Service</a></li>
                <li><a href="#Misc">Misc.</a></li>
              </ul>
            </div>
          </div>



        </div>
        <div class="column right-panel">
          <div class="content">


            <!--About Me-->
            <h2 id="Intro">About Me</h2>
            <p>
              I am currently a student researcher at <a href="http://www.lightillusions.com/"><b>Lightillusions Robotics Team</b></a> and <a href="https://air.tsinghua.edu.cn/en/"><b>Institute for AI Industry Research (AIR), Tsinghua University</b></a>. 
              I am fortunate to work closely with <a href="https://ece.hkust.edu.hk/pingtan">Prof. Ping Tan</a> from <a href="https://hkust.edu.hk/">HKUST</a>, <a href="https://www.xxlong.site/">Dr. Xiaoxiao Long</a> from <a href="https://www.hku.hk/">HKU</a>, and <a href="https://sites.google.com/view/fromandto">Prof. Hao Zhao</a> from <a href="https://www.discover-lab.com/">DISCOVER Lab</a>. 
              Previously, I was a visiting student at <a href="http://english.ia.cas.cn/">Institute of Automation, Chinese Academy of Sciences</a> in my senior year.
              And I got my B.Eng. in Mechatronics Engineering from Beijing University of Civil Engineering and Architecture.
              <br><br>
              I am an active member of <a href="https://anysyn3d.github.io/">AnySyn3D</a>, a non-profit research interest group comprising individuals with a strong interest in exploring research problems and cutting-edge technologies in any topics of 3D.
              <br><br>
              <strong>I am actively looking for the Ph.D opportunity in Fall 2025, here is my <a href="https://drive.google.com/file/d/1nLeCwwlKgRKYNwyiYaKWGuzORINrSvCR/view?usp=drive_link">Curriculum Vitae</a>.</strong>
            </p>

            <!--Research-->
            <h2 id="Research">Research</h2>
            <p>
               My long-term research goal is to build <strong>Embodied Intelligent Systems</strong> that connect Humansüë´- Machinesü§ñ - Real Worldüåè by perception, simulation, and interaction. 
               I believe the key lies in leveraging human <b>language</b>üó£Ô∏è to help <b>robots</b> use <b>3D visual information</b> to learn how to perceive, reason, and manipulate in both virtual and real world. 
              <br>
               So I am currently focusing on <strong>{3D Vision, Robotics, Graphics} for Embodied AI</strong>:
            </p>
            <ul>
              <li>üëÄ<strong>3D Vision for Embodied Perception</strong>
                <br>3D Scene Understanding; 3D Vision-Language Model (e.g.grounding, dense captioning, VQA); <S>Anomaly Detection</S>.
	      <li>ü§ñ<strong>Robotics for Embodied Interaction</strong>
                <br>Multi-task Manipulation; Long-horizon Mobile Manipulation; Autonomous Driving.
              <li>ü™Ö<strong>Graphics for Embodied Simulation</strong>
                <br>3D Reconstruction and Editing, Video Generation.
            </ul>

            <!--Publications-->

            <h2 id="Publications" style="display: inline;">Publications</h2>
            <span style="display: inline; color:#999999; text-decoration:none; font-size: 15px; margin-left: 1rem;">
              (‚Ä†: corresponding author; *: equal contribution)
            </span>
            <p></p>
            <!--List of publications-->
            <article class="columns">
              <div class="column is-3">
                <figure class="image">
                  <img src="images/publications/ProGEM_main.png">
                </figure>
              </div>
              <div class="column">
                <div class="content">
                  <p>
                    <b>ProGEM: Probing Generalizable and Efficient Feature Fields Distillation for Multi-Task Robotic Manipulation</b><br>
                    		<strong>Weize Li</strong>,
			                	<a>Zhen Chen</a>,
			                 	<a>Robin Ananda</a>,
			                	<a>Binxu Wu</a>,
		                		<a>Qi Lu</a>,
                        <a>Qianyao Xu</a>,
                        <a>Jiaying Li</a>,
			                	<a>Yingqing Xu</a>.</em><br>
                    <i>CVPR 2025 Submission</i><br>
                    <a href="https://arxiv.org/abs/" target="_blank">[Coming Soon]</a>
                    <!-- <a href="https://github.com/EricLee0224/awesome-nerf-editing" target="_blank">[Website]</a><br> -->
	                  <!-- <p>This is an ongoing survey paper with awesome list repo.</p> -->
                  </p>
                </div>
              </div>
            </article>


	          <article class="columns">
              <div class="column is-3">
                <figure class="image">
                  <img src="images/publications/wm-teaser.png">
                </figure>
              </div>
              <div class="column">
                <div class="content">
                  <p>
                    <b>SCA-WM: Structure-aware Collaboratively Aligned World Model</b><br>
                  	  	<a href="https://scholar.google.com/citations?user=uUd5v2cAAAAJ&hl=en">Bu Jin<sup>*</sup></a>,
			                	<a>Zhenxin Zhu<sup>*</sup></a>,
		                	 	<a>Baihan Yang<sup>*</sup></a>,
			                 	<strong>Weize Li</strong>,
			                	<a>Junpeng Jiang</a>,
		                  	<a href="https://c7w.tech/about/">Huan-ang Gao</a>,
		                   	<a>Haiyang Sun</a>,
		        	        	<a>Kun Zhan</a>,
		                		<a href="https://scholar.google.com/citations?user=Z_QY_VwAAAAJ">Peng Jia</a>,
		                	 	<a href="https://sites.google.com/view/fromandto">Hao Zhao</a>.</em><br>
                    <i>ICRA 2025 Submission</i><br>
                    <a href="https://arxiv.org/abs/" target="_blank">[Coming Soon]</a>
<!--                     <a href="https://openreview.net/forum?id=kxFKgqwFNk" target="_blank">[OpenReview]</a> -->
<!--                     <a href="https://github.com/EricLee0224/PAD" target="_blank">[Code]</a><br> -->
                    <!-- <p>We introduce pose-agnostic setting to 3D-aware object anomaly detection problem with MAD dataset, propose the NeRF-based anomaly detection framework: OmniposeAD.</p> -->
                  </p>
                </div>
              </div>
            </article>
		  
            <!--List of publications-->
            <article class="columns">
              <div class="column is-3">
                <figure class="image">
                  <img src="images/publications/survey_teaser_new2.png">
                </figure>
              </div>
              <div class="column">
                <div class="content">
                  <p>
                    <b>Radiance Field-Based 3D Editing: A Survey</b><br>
                    		<strong>Weize Li<sup>*</sup></strong>,
			                	<a href="https://tianshukuai.github.io/">Tianshu Kuai<sup>*</sup></a>,
			                 	<a href="https://c7w.tech/about/">Huan-ang Gao</a>,
			                	<a href="https://xiangyueliu.github.io/">Xiangyue Liu</a>,
		                		<a href="https://scholar.google.com/citations?user=Wn2Aic0AAAAJ&hl=en">Yuhang Zheng</a>,
			                	<a href="https://scholar.google.com/citations?user=anGhGdYAAAAJ&hl=en">Yupeng Zheng</a>, etc.</em><br>
                    <i>T-PAMI 2024 Submission</i><br>
                    <a href="https://arxiv.org/abs/" target="_blank">[arXiv]</a>
                    <a href="https://github.com/EricLee0224/awesome-nerf-editing" target="_blank">[Website]</a><br>
	                  <!-- <p>This is an ongoing survey paper with awesome list repo.</p> -->
                  </p>
                </div>
              </div>
            </article>


            <article class="columns">
              <div class="column is-3">
                <figure class="image">
                  <img src="images/publications/tod3cap.png">
                </figure>
              </div>
              <div class="column">
                <div class="content">
                  <p>
                    <b>TOD3Cap: Towards 3D Dense Captioning in Outdoor Scenes</b><br>
                    		<a href="https://scholar.google.com/citations?user=uUd5v2cAAAAJ&hl=en">Bu Jin</a>,
				                <a href="https://scholar.google.com/citations?user=anGhGdYAAAAJ&hl=en">Yupeng Zheng<sup>‚Ä†</sup></a>,
				                <a href="https://github.com/Philipflyg">Pengfei Li</a>,
				                <strong>Weize Li</strong>,
				                <a href="https://scholar.google.com/citations?user=Wn2Aic0AAAAJ&hl=en">Yuhang Zheng</a>,
		                    <a>Sujie Hu</a>,
				                <a href="https://liuxinyv.github.io/">Xinyu Liu</a>,
			  	              <a>Jinwei Zhu</a>,
			  	              <a href="https://scholar.google.com/citations?user=4PXGeaYAAAAJ">Zhijie Yan</a>,
			 	                <a>Haiyang Sun</a>,
				                <a>Kun Zhan</a>,
				                <a href="https://scholar.google.com/citations?user=Z_QY_VwAAAAJ">Peng Jia</a>,
		                    <a href="https://www.xxlong.site/">Xiaoxiao Long</a>,
		                    <a href="https://air.tsinghua.edu.cn/en/info/1046/1621.htm">Yilun Chen</a>,
		                    <a href="https://sites.google.com/view/fromandto">Hao Zhao</a>.</em><br>
                    <i>ECCV 2024 (<a style="color: red;">Poster</a>)</i><br>
                    <a href="https://arxiv.org/abs/2403.19589" target="_blank">[arXiv]</a>
                    <a href="https://github.com/jxbbb/TOD3Cap" target="_blank">[Code]</a><br>
                    [<a style="color: red;">Special Ack.</a> to <a href="https://daveredrum.github.io/">Dave Zhenyu Chen</a>@TUM for valuable proofreading and insightful suggestions.</a>]
	                  <!-- <p>We introduce the new task of outdoor 3D dense captioning with TOD3Cap dataset; We propose TOD3Cap network, leveraging the BEV representation to encode sparse outdoor scenes, and combine Relation Q-Former with LLaMA-Adapter to dense captioning in the open-world.</p> -->
                  </p>
                </div>
              </div>
            </article>


            <article class="columns">
              <div class="column is-3">
                <figure class="image">
                  <img src="images/publications/pad.png">
                </figure>
              </div>
              <div class="column">
                <div class="content">
                  <p>
                    <b>PAD: A Dataset and Benchmark for Pose-agnostic Anomaly Detection</b><br>
			                	<strong>Weize Li<sup>*</sup></strong>,
                      	<a href="https://scholar.google.com/citations?user=CMYTxUEAAAAJ&hl=en/">Qiang Zhou<sup>*</sup></a>,
		         	        	<a href="https://jianglh-whu.github.io/">Lihan Jiang</a>,
		           	      	<a href="https://github.com/Cross-ZBuild">Guoliang Wang</a>,
	  	    	  	        <a href="https://air.tsinghua.edu.cn/en/info/1046/1196.htm">Guyue Zhou</a>,
			                	<a href="https://www.shanghangzhang.com/">Shanghang Zhang</a>,
	     	      		      <a href="https://sites.google.com/view/fromandto">Hao Zhao</a>.</em><br>
                    <i>NeurIPS 2023 Dataset and Benchmark Track (<a style="color: red;">Poster</a>)</i><br>
                    <a href="https://arxiv.org/abs/2310.07716" target="_blank">[arXiv]</a>
                    <a href="https://openreview.net/forum?id=kxFKgqwFNk" target="_blank">[OpenReview]</a>
                    <a href="https://github.com/EricLee0224/PAD" target="_blank">[Code]</a><br>
                    <!-- <p>We introduce pose-agnostic setting to 3D-aware object anomaly detection problem with MAD dataset, propose the NeRF-based anomaly detection framework: OmniposeAD.</p> -->
                  </p>
                </div>
              </div>
            </article>


            <article class="columns">
              <div class="column is-3">
                <figure class="image">
                  <img src="images/publications/irflmdnn.png">
                </figure>
              </div>
              <div class="column">
                <div class="content">
                  <p>
                    <b>IRFLMDNN: Hybrid Model for PMU Data Anomaly Detection and Re-filling with Improved Random Forest and Levenberg Marquardt Algorithm Optimized Dynamic Neural Network</b><br>
                    		<a href="http://faculty.bucea.edu.cn/pub/yumiao/">Miao Yu<sup>‚Ä†</sup></a>,
				                <a>Chenyu Yang<sup>*</sup></a>,
		                		<strong>Weize Li<sup>*</sup></strong>,
			                	<a>Weijie Du</a>,
			                	<a>Jinglin Li</a>.</em><br>
                    <i>Neural Computing and Application 2023</i><br>
                    <a href="https://dl.acm.org/doi/abs/10.1007/s00521-023-08571-4" target="_blank">[Paper]</a><br>
                    <!-- <p>We propose a hybrid model of improved RF + DNN to extract time-series features and classify anomalies in power system data.</p> -->
                  </p>
                </div>
              </div>
            </article>

            <!--Projects-->

            <h2 id="Projects">
              Projects
              <span style="font-size: 1rem;margin-left: 1rem;position: relative;bottom: .2rem;">
              </span>
            </h2>

            <article class="columns">
              <div class="column is-3">
                <figure class="image">
                  <img src="images/misc/zero12car.png">
                </figure>
              </div>
              <div class="column">
                <div class="content">
                  <p>
                    <b>Zero1-to-Car: Finetuning Zero1-to-3 for Single Vehicle Image to 3D Generation</b><br>
              			<!-- <strong>Weize Li</strong></em><br> -->
                    <i>AIR Research Project 2023</i><br>
                    <a href="https://github.com/" target="_blank">[Coming soon]</a><br>
                    <!-- <p>Investigated one‚Äëimage‚Äëto‚Äë3D methods like Zero1‚Äëto‚Äë3 to enhance the quality of multi‚Äëview car instances in simulation scenes, with a focus on fine‚Äëtuning models using the ‚ÄùCar‚Äù labeled 3D assets from the Objaverse dataset.</p> -->
                  </p>
                </div>
              </div>
            </article>


            <article class="columns">
              <div class="column is-3">
                <figure class="image">
                  <img src="images/misc/mcadtr.png">
                </figure>
              </div>
              <div class="column">
                <div class="content">
                  <p>
                    <b>McADTR: Multi-class Anomaly Detection TRansformer with Heterogenous Knowledge Distillation</b><br>
								    <!-- <strong>Weize Li</strong></em><br> -->
                    <i>AIR Summer Research 2022</i><br>
                    <a href="https://github.com/EricLee0224/McADTR" target="_blank">[Code]</a><br>
                    <!-- <p>This project proposes a unified framework for visual anomaly detection based on heterogeneous knowledge distillation. The One-model-all class framework merges CNN and ViT with class-specific learnable query to enable mutually facilitated learning of anomalous features across multi-class samples.</p> -->
                  </p>
                </div>
              </div>
            </article>


            <!--Experiences-->
            <!-- <h2 id="Experiences" style="margin-bottom: 25px;">Experiences</h2>

            <article class="columns">
              <div class="column is-3">
                <figure class="image">
                  <img src="images/misc/tongji.png" class="img-logo">
                </figure>
              </div>
              <div class="column">
                <div class="content">
                  <p>
                    <b>B.S. in Tongji University</b><br>
                    Time: Aug 2019 - Jun 2023.  
                  </p>
                </div>
              </div>
            </article>

            <article class="columns">
              <div class="column is-3">
                <figure class="image">
                  <img src="images/misc/sjtu.png" class="img-logo">
                </figure>
              </div>
              <div class="column">
                <div class="content">
                  <p>
                    <b>Ph.D in Shanghai Jiao Tong University</b><br>
                    Time: Sept 2023 - Present.
                  </p>
                </div>
              </div>
            </article>

            <article class="columns">
              <div class="column is-3">
                <figure class="image">
                  <img src="images/misc/ailab.png" class="img-logo">
                </figure>
              </div>
              <div class="column">
                <div class="content">
                  <p>
                    <b>Research Intern</b> | Shanghai Artificial Intelligence Lab(<a href="https://www.shlab.org.cn/" target="_blank" rel="noopener">PJLAB</a>)<br>
                    Time: Nov 2022 - Present.
                  </p>
                </div>
              </div>
            </article> -->
            
            <!-- Patents -->
            <h2 id="Patents" onclick="togglePatents()">Patents
              <span style="display: inline; color:#999999; text-decoration:none; font-size: 15px; margin-left: 1rem;">
                (click to show all)
              </span>
            </h2>
            <div id="patentsContent" style="display:none;">
              <ul>
                <li><b>Power low frequency oscillation data anomaly monitoring system v1.0[s]</b>, CN Software Patent No.2022SR0277090</li>
                <li><b>Power low frequency oscillation data acquisition system v1.0[s]</b>, CN Software Patent No.2022SR0281546</li>
              </ul>
            </div>

            <!--Awards-->
            <h2 id="Awards">Awards</h2>
            <ul>
              <li>[2022] <strong>Best Undergraduate Dissertation Award, Beijing Education Commission (top 1% in 130,000 students).</strong>
              <li>[2022] Silver Award, Beijing Challenge Cup: Entrepreneurial Plan Competition in AI System Track (Rank.2)
            </ul>
            
            <!--Academic Service-->
            <h2 id="Service">Service</h2>
            <p>
              I served / was delegated as Reviewer for NeurIPS‚Äô23, CVPR‚Äô24, IJCV.
            </p>

            <!-- Misc. -->
            <h2 id="Misc">Misc.</h2>
            <p>
              Outside of research, I enjoy playing football‚öΩ, fitnessüí™ and photographyüì∑. I am a member of the Certified Referee of the Chinese Football Association. I am also a big fan of Taylor Swiftü¶ã.
            </p>
            <p>
              Meet our workmates:
              <figure class="image">
                <img src="images/misc/workmates.jpg">
              </figure>

            </p>
            <!-- To be add? -->

          </div>
        </div>
      </div>
    </div>



    <!-- Footer -->
	<footer class="container">
	  <br><hr>
	  <!-- counts ip -->
	  <div id="clustrmaps-widget" style="width:10%; margin: 0 auto; text-align: center;">
	    <script type="text/javascript" id="clstr_globe" src="//clustrmaps.com/globe.js?d=b7mtyQom9p7zsZIJHjY71xt4m7fiicjvzctV6CkNA-s"></script>
	  </div>
	  <div class="row" style="text-align: center;">
	    ¬© 2024 Weize Li<br>Last update: Oct. 2024
	  </div>
	</footer>
  </section>


  <script>

    var $hashList = $('.menu-list a'), offsetList, maxScrollHeight;

    $('#sidebar').on('click', 'a', function(){
      activate($(this))
    });
    
    $(window).on('resize', debounce(calculateBoundary, 300));

    $(document).on('scroll', debounce(judgeScroll, 300));

    calculateBoundary();
    judgeScroll();
    
    function togglePatents() {
    var content = document.getElementById("patentsContent");
    if (content.style.display === "none") {
      content.style.display = "block";
    } else {
      content.style.display = "none";
    }
  }

    function  calculateBoundary() {
      offsetList = $hashList.map(function(idx, ele){
        return $(ele.hash).offset().top
      });
      maxScrollHeight = $(document).height() - $(window).height()
    }
    
    function judgeScroll() {
      var tps = $("html").scrollTop()
              ? $("html").scrollTop()
              : $("body").scrollTop(),
              len = offsetList.length;
      if(tps >= maxScrollHeight-10){
        activate($hashList.eq(len-1));
        return
      }
      for(var i=0; i<len; i++){
       if(tps+50<offsetList[i]){
          activate($hashList.eq(Math.max(0,i-1)));
          return
        }
      }
    }

    function activate(ele){
      $hashList.removeClass('is-active');
      ele.addClass('is-active');
    }

    function debounce(fn, delay) {
      var timeout = null;
      return function () {
        var args = arguments;
        var context = this;
        if (!timeout) {
          timeout = setTimeout(function () {
            timeout = 0;
            return fn.apply(context, args);
          }, delay);
        }
      };
    }



  </script>


</body>

</html>
